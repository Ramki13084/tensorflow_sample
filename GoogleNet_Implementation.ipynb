{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogleNet-Implementation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNmhDYv+r+yy8TJWOZ8eCS2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ramki13084/tensorflow_sample/blob/main/GoogleNet_Implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_yHGL138G9e"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras import backend\n",
        "from tensorflow.keras.layers import Concatenate"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8gGB0gv_EQt",
        "outputId": "aac6d320-2ad8-49da-d57b-a339efb6ef9e"
      },
      "source": [
        "!pip install tf-slim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tf-slim\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[K     |████████████████████████████████| 352 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from tf-slim) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.2.2->tf-slim) (1.15.0)\n",
            "Installing collected packages: tf-slim\n",
            "Successfully installed tf-slim-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXLoCCiVFIz"
      },
      "source": [
        "#parameters\n",
        "output_class = 10 # no of classes defined as 10. this parameter is customizable."
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TIv_fE88Ij9"
      },
      "source": [
        "def conv2d_bn(x,\n",
        "              filters,\n",
        "              num_row,\n",
        "              num_col,\n",
        "              padding='same',\n",
        "              strides=(1, 1),\n",
        "              name=None):\n",
        "  \"\"\"Utility function to apply conv + BN.\n",
        "  Args:\n",
        "   1st input x: input tensor.\n",
        "   2nd input filters: filters in `Conv2D`.\n",
        "   3rd input num_row: height of the convolution kernel.\n",
        "   4th input num_col: width of the convolution kernel.\n",
        "   5th input  padding: padding mode in `Conv2D`.\n",
        "   6th input strides: strides in `Conv2D`.\n",
        "    name: name of the ops; will become `name + '_conv'`\n",
        "      for the convolution and `name + '_bn'` for the\n",
        "      batch norm layer.\n",
        "  Returns:\n",
        "    Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "  \"\"\"\n",
        "  if name is not None:\n",
        "    bn_name = name + '_bn'\n",
        "    conv_name = name + '_conv'\n",
        "  else:\n",
        "    bn_name = None\n",
        "    conv_name = None\n",
        "  if backend.image_data_format() == 'channels_first':\n",
        "    bn_axis = 1\n",
        "  else:\n",
        "    bn_axis = 3\n",
        "  x = layers.Conv2D(\n",
        "      filters, (num_row, num_col),\n",
        "      strides=strides,\n",
        "      padding=padding,\n",
        "      use_bias=False,\n",
        "      name=conv_name)(\n",
        "          x)\n",
        "  x = layers.BatchNormalization(axis=bn_axis, scale=False, name=bn_name)(x)\n",
        "  x = layers.Activation('relu', name=name)(x)\n",
        "  return x"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDwXjVn9UJ-l",
        "outputId": "246ad7b8-130e-45a2-fa53-73643071a5ee"
      },
      "source": [
        "x = np.arange(20).reshape(2,2,5)\n",
        "print(x)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[ 0  1  2  3  4]\n",
            "  [ 5  6  7  8  9]]\n",
            "\n",
            " [[10 11 12 13 14]\n",
            "  [15 16 17 18 19]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNIks3oLUKWc",
        "outputId": "099f9808-2619-4f98-c9b8-8c215ff0bbbe"
      },
      "source": [
        "y = np.arange(20, 40).reshape(2, 2, 5)\n",
        "print(y)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[20 21 22 23 24]\n",
            "  [25 26 27 28 29]]\n",
            "\n",
            " [[30 31 32 33 34]\n",
            "  [35 36 37 38 39]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plZzRP8KUKhx",
        "outputId": "d0119a10-697a-4e02-ac2c-dbf47b1b92f1"
      },
      "source": [
        "concat = tf.keras.layers.Concatenate(axis=-1)([x, y])\n",
        "concat.shape\n",
        "print(concat)  # IF axis is given -1 then both x and y tensor should have same shape.\n",
        "# IF axis is given 1 then x and y tensor should have same tensor shape in y axis."
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[[ 0  1  2  3  4 20 21 22 23 24]\n",
            "  [ 5  6  7  8  9 25 26 27 28 29]]\n",
            "\n",
            " [[10 11 12 13 14 30 31 32 33 34]\n",
            "  [15 16 17 18 19 35 36 37 38 39]]], shape=(2, 2, 10), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QyD7Dwr4PRIV"
      },
      "source": [
        "def inception(x, filters):\n",
        "    # 1x1\n",
        "    path1 = conv2d_bn(x,filters[0],1,1)\n",
        "\n",
        "    # 1x1->3x3\n",
        "    path2 = conv2d_bn(x,filters[1][0],1,1)\n",
        "    path2 = conv2d_bn(path2,filters[1][1], 3,3)\n",
        "    \n",
        "    # 1x1->5x5\n",
        "    path3 = conv2d_bn(x,filters[2][0],1,1)\n",
        "    path3 = conv2d_bn(path3,filters[2][1], 5,5)\n",
        "\n",
        "    # 3x3->1x1\n",
        "    path4 = MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(x)\n",
        "    path4 = conv2d_bn(path4,filters[3],1,1)(path4)\n",
        "\n",
        "    return Concatenate(axis=-1)([path1,path2,path3,path4])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7i3nlhkRUsjN"
      },
      "source": [
        "def auxiliary(x, name=None):\n",
        "    layer = AveragePooling2D(pool_size=(5,5), strides=3, padding='valid')(x)\n",
        "    layer = conv2d_bn(layer,128,1,1)\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dense(units=256, activation='relu')(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(units=output_class, activation='softmax', name=name)(layer)\n",
        "    return layer"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AdcM5-wVQbs"
      },
      "source": [
        "def googlenet():\n",
        "    layer_in = Input(shape=IMAGE_SHAPE)\n",
        "    \n",
        "    # stage-1\n",
        "    layer = conv2d_bn(layer_in,64,7,7,padding='same',strides=(2,2))\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    layer = BatchNormalization()(layer)\n",
        "\n",
        "    # stage-2\n",
        "    layer = conv2d_bn(layer,64,1,1)\n",
        "    layer = conv2d_bn(layer,192,3,3)\n",
        "    layer = BatchNormalization()(layer)\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "\n",
        "    # stage-3\n",
        "    layer = inception(layer, [ 64,  (96,128), (16,32), 32]) #3a\n",
        "    layer = inception(layer, [128, (128,192), (32,96), 64]) #3b\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    \n",
        "    # stage-4\n",
        "    layer = inception(layer, [192,  (96,208),  (16,48),  64]) #4a\n",
        "    aux1  = auxiliary(layer, name='aux1')\n",
        "    layer = inception(layer, [160, (112,224),  (24,64),  64]) #4b\n",
        "    layer = inception(layer, [128, (128,256),  (24,64),  64]) #4c\n",
        "    layer = inception(layer, [112, (144,288),  (32,64),  64]) #4d\n",
        "    aux2  = auxiliary(layer, name='aux2')\n",
        "    layer = inception(layer, [256, (160,320), (32,128), 128]) #4e\n",
        "    layer = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(layer)\n",
        "    \n",
        "    # stage-5\n",
        "    layer = inception(layer, [256, (160,320), (32,128), 128]) #5a\n",
        "    layer = inception(layer, [384, (192,384), (48,128), 128]) #5b\n",
        "    layer = AveragePooling2D(pool_size=(7,7), strides=1, padding='valid')(layer)\n",
        "    \n",
        "    # stage-6\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dropout(0.4)(layer)\n",
        "    layer = Dense(units=256, activation='linear')(layer)\n",
        "    main = Dense(units=CLASS_NUM, activation='softmax', name='main')(layer)\n",
        "    \n",
        "    model = Model(inputs=layer_in, outputs=[main, aux1, aux2])\n",
        "    \n",
        "    return model"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40PCMzkk8IpE"
      },
      "source": [
        "def InceptionV3(\n",
        "    include_top=True,\n",
        "    weights='imagenet',\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=1000,\n",
        "    classifier_activation='softmax'):\n",
        "\n",
        "        # Determine proper input shape\n",
        "        input_shape = imagenet_utils.obtain_input_shape(\n",
        "            input_shape,\n",
        "            default_size=299,\n",
        "            min_size=75,\n",
        "            data_format=backend.image_data_format(),\n",
        "            require_flatten=include_top,\n",
        "            weights=weights)\n",
        "\n",
        "        if input_tensor is None:\n",
        "          img_input = layers.Input(shape=input_shape)\n",
        "        else:\n",
        "          if not backend.is_keras_tensor(input_tensor):\n",
        "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
        "          else:\n",
        "            img_input = input_tensor\n",
        "\n",
        "        if backend.image_data_format() == 'channels_first':\n",
        "          channel_axis = 1\n",
        "        else:\n",
        "          channel_axis = 3\n",
        "\n",
        "        x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding='valid') # (297-3)/2 + 1=147+1 = 148\n",
        "        x = conv2d_bn(x, 32, 3, 3, padding='valid') # (148-3)/1+1 = 146\n",
        "        x = conv2d_bn(x, 64, 3, 3) # (146+2-3)/1+1 = 146\n",
        "        x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x) # 146/2 = 73\n",
        "\n",
        "        x = conv2d_bn(x, 80, 1, 1, padding='valid') # (73-1)/1+1 = 73\n",
        "        x = conv2d_bn(x, 192, 3, 3, padding='valid') # (73-3)/1+1=71\n",
        "        x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x) # (71+2(1)-3)/2 =35\n",
        "\n",
        "        # mixed 0: 35 x 35 x 256\n",
        "        branch1x1 = conv2d_bn(x, 64, 1, 1) \n",
        "\n",
        "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "        x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed0')\n",
        "\n",
        "        # mixed 1: 35 x 35 x 288\n",
        "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "        x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed1')\n",
        "\n",
        "        # mixed 2: 35 x 35 x 288\n",
        "        branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "        branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "        branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "        x = layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed2')\n",
        "\n",
        "        # mixed 3: 17 x 17 x 768\n",
        "        branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "        branch3x3dbl = conv2d_bn(\n",
        "            branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "        branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "        x = layers.concatenate([branch3x3, branch3x3dbl, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed3')\n",
        "\n",
        "        # mixed 4: 17 x 17 x 768\n",
        "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "        branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "        branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed4')\n",
        "\n",
        "        # mixed 5, 6: 17 x 17 x 768\n",
        "        for i in range(2):\n",
        "          branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "          branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "          branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
        "          branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "          branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
        "          branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "          branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
        "          branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "          branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "          branch_pool = layers.AveragePooling2D((3, 3),\n",
        "                                                strides=(1, 1),\n",
        "                                                padding='same')(\n",
        "                                                    x)\n",
        "          branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "          x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "                                axis=channel_axis,\n",
        "                                name='mixed' + str(5 + i))\n",
        "\n",
        "        # mixed 7: 17 x 17 x 768\n",
        "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "        branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "        branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding='same')(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed7')\n",
        "\n",
        "        # mixed 8: 8 x 8 x 1280\n",
        "        branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "        branch3x3 = conv2d_bn(branch3x3, 320, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "        branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "        branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "        branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "        branch7x7x3 = conv2d_bn(\n",
        "            branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')\n",
        "\n",
        "        branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "        x = layers.concatenate([branch3x3, branch7x7x3, branch_pool],\n",
        "                              axis=channel_axis,\n",
        "                              name='mixed8')\n",
        "\n",
        "        # mixed 9: 8 x 8 x 2048\n",
        "        for i in range(2):\n",
        "          branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "          branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "          branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "          branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "          branch3x3 = layers.concatenate([branch3x3_1, branch3x3_2],\n",
        "                                        axis=channel_axis,\n",
        "                                        name='mixed9_' + str(i))\n",
        "\n",
        "          branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "          branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "          branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "          branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "          branch3x3dbl = layers.concatenate([branch3x3dbl_1, branch3x3dbl_2],\n",
        "                                            axis=channel_axis)\n",
        "\n",
        "          branch_pool = layers.AveragePooling2D((3, 3),\n",
        "                                                strides=(1, 1),\n",
        "                                                padding='same')(\n",
        "                                                    x)\n",
        "          branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "          x = layers.concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "                                axis=channel_axis,\n",
        "                                name='mixed' + str(9 + i))\n",
        "        if include_top:\n",
        "          # Classification block\n",
        "          x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
        "          imagenet_utils.validate_activation(classifier_activation, weights)\n",
        "          x = layers.Dense(classes, activation=classifier_activation,\n",
        "                          name='predictions')(x)\n",
        "        else:\n",
        "          if pooling == 'avg':\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "          elif pooling == 'max':\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "        # Ensure that the model takes into account\n",
        "        # any potential predecessors of `input_tensor`.\n",
        "        if input_tensor is not None:\n",
        "          inputs = layer_utils.get_source_inputs(input_tensor)\n",
        "        else:\n",
        "          inputs = img_input\n",
        "        # Create model.\n",
        "        model = training.Model(inputs, x, name='inception_v3')\n",
        "\n",
        "        # Load weights.\n",
        "        if weights == 'imagenet':\n",
        "          if include_top:\n",
        "            weights_path = data_utils.get_file(\n",
        "                'inception_v3_weights_tf_dim_ordering_tf_kernels.h5',\n",
        "                WEIGHTS_PATH,\n",
        "                cache_subdir='models',\n",
        "                file_hash='9a0d58056eeedaa3f26cb7ebd46da564')\n",
        "          else:\n",
        "            weights_path = data_utils.get_file(\n",
        "                'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
        "                WEIGHTS_PATH_NO_TOP,\n",
        "                cache_subdir='models',\n",
        "                file_hash='bcbd6486424b2319ff4ef7d526e38f63')\n",
        "          model.load_weights(weights_path)\n",
        "        elif weights is not None:\n",
        "          model.load_weights(weights)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpd1h0km8It8"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKDIBS0K8IyJ"
      },
      "source": [
        ""
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaFoPc0F8I16"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e_MwRTpz8I59"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Q78Z-yI8I9K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yo-oZZVs8JAg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8re-VVC8JIa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2pMZF4k8JMv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiVlNNgX8JQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYz6XOJy8JUi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHTz3e2o8JZP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWEOeBzp8Jby"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17qzHZ1I8JfM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw043RRy8Ji3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sF8DWMB8Jmt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLUuT_Fu8JqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdPDy5rF8JuD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A86uczaf8JyJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGIZx92A8J2C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDu4gJFf8J5t"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nzWBT2i88J96"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRkKs5q_8KB6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXDjRU7R8KFE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zz6yjgve8KJQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5S3YFof8KMu"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9iFEtWf8KQU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC6Q-RXM8KTl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxVhZKL68KW6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7LgKesc8Kas"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}